{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please input the number of lanes:\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from LaneInput import LaneInput  # Class to input lane regions\n",
    "from PSMorg import PEDESTRIANESTIMATOR # Updated SpeedEstimator2 class with time increment\n",
    "from time_utils import increment_time, get_time_from_xml  # Import utility functions\n",
    "\n",
    "# Initialize the YOLO model for object detection\n",
    "model = YOLO(\"best(3).pt\")  # Replace with the path to your YOLO model\n",
    "names = model.model.names  # List of class names for the YOLO model\n",
    "\n",
    "# Initialize video capture\n",
    "video_path = \"C0148.mp4\"  # Replace with the path to your video\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "assert cap.isOpened(), f\"Error reading video file {video_path}\"\n",
    "\n",
    "# Get video properties (width, height, and FPS)\n",
    "w, h, fps = (int(cap.get(x)) for x in (cv2.CAP_PROP_FRAME_WIDTH, \n",
    "                                      cv2.CAP_PROP_FRAME_HEIGHT, \n",
    "                                      cv2.CAP_PROP_FPS))\n",
    "\n",
    "# Video writer to save the processed video with lane detection\n",
    "output_video = \"lane_detection_output.avi\"\n",
    "video_writer = cv2.VideoWriter(output_video, \n",
    "                               cv2.VideoWriter_fourcc(*\"mp4v\"), \n",
    "                               fps, (w, h))\n",
    "\n",
    "# Initialize LaneInput to capture lane points\n",
    "lane_input = LaneInput()\n",
    "\n",
    "# Capture the first frame from the video to input lane points\n",
    "success, first_frame = cap.read()\n",
    "if not success:\n",
    "    raise ValueError(\"Failed to read the first frame from the video.\")\n",
    "\n",
    "# Input the lane regions in the first frame\n",
    "lane_input.input_lanes(first_frame)\n",
    "lane_regions = lane_input.get_lanes()  # Get the captured lane regions\n",
    "if not lane_regions:\n",
    "    raise ValueError(\"No lane regions captured. Please ensure lanes are defined.\")\n",
    "\n",
    "print(\"Captured Lane Regions:\", lane_regions)\n",
    "\n",
    "# Load initial time from the XML file\n",
    "xml_file = r\"E:\\learn phython\\speed 2\\Speed-detection-of-vehicles\\C0148M01.XML\"\n",
    "current_time = get_time_from_xml(xml_file)\n",
    "\n",
    "# Initialize SpeedEstimator2\n",
    "lane_estimator = SpeedEstimator2(\n",
    "    names=names,\n",
    "    lane_regions=lane_regions,\n",
    "    view_img=True,  # Display image flag\n",
    "    target_x=500,   # Define the X-coordinate target for lane estimation\n",
    "    csv_file=\"lane_log.csv\"  # Define the CSV file for logging\n",
    ")\n",
    "\n",
    "# Frame processing\n",
    "frame_counter = 0\n",
    "skip_frames = 10  # Number of frames to skip after processing one frame\n",
    "\n",
    "# Main loop for processing each video frame\n",
    "while cap.isOpened():\n",
    "    success, im0 = cap.read()  # Read the next frame\n",
    "    if not success:\n",
    "        print(\"Video processing completed or frame not available.\")\n",
    "        break\n",
    "\n",
    "    # Process every (skip_frames + 1)-th frame\n",
    "    if frame_counter % (skip_frames + 1) == 0:\n",
    "        # Perform object detection and tracking using the YOLO model\n",
    "        tracks = model.track(im0, persist=True)\n",
    "        \n",
    "        # Increment the current time based on the number of frames skipped\n",
    "        current_time = increment_time(current_time, skip_frames + 1, fps)\n",
    "        \n",
    "        # Pass the tracks and the frame to SpeedEstimator2's check_and_log_lanes function\n",
    "        im0 = lane_estimator.process_frame(im0, tracks, current_time)\n",
    "\n",
    "        # Display the processed frame with lane estimation\n",
    "        cv2.imshow(\"Live Output\", im0)\n",
    "\n",
    "        # Write the processed frame to the output video\n",
    "        video_writer.write(im0)\n",
    "\n",
    "    # Increment frame counter\n",
    "    frame_counter += 1\n",
    "\n",
    "    # Break the loop if the 'q' key is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        print(\"Processing terminated by user.\")\n",
    "        break\n",
    "\n",
    "# Release video capture and writer resources\n",
    "cap.release()\n",
    "video_writer.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(f\"Processing complete. Output saved to {output_video}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(318, 427), (687, 417), (1081, 389)]\n",
      "\n",
      "0: 384x640 6 motobikes, 2 pedestrians, 8 sedans, 650.5ms\n",
      "Speed: 0.0ms preprocess, 650.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 motobikes, 2 pedestrians, 7 sedans, 630.4ms\n",
      "Speed: 17.7ms preprocess, 630.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 motobikes, 4 pedestrians, 7 sedans, 612.9ms\n",
      "Speed: 0.0ms preprocess, 612.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 motobike, 5 pedestrians, 6 sedans, 599.3ms\n",
      "Speed: 0.0ms preprocess, 599.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 motobikes, 3 pedestrians, 5 sedans, 630.5ms\n",
      "Speed: 0.0ms preprocess, 630.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 pedestrians, 5 sedans, 654.5ms\n",
      "Speed: 0.0ms preprocess, 654.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 motobike, 4 pedestrians, 4 sedans, 598.5ms\n",
      "Speed: 0.0ms preprocess, 598.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 motobikes, 3 pedestrians, 4 sedans, 596.5ms\n",
      "Speed: 0.0ms preprocess, 596.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 motobike, 4 pedestrians, 4 sedans, 598.6ms\n",
      "Speed: 0.0ms preprocess, 598.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 motobike, 5 pedestrians, 5 sedans, 600.3ms\n",
      "Speed: 3.0ms preprocess, 600.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 motobike, 5 pedestrians, 5 sedans, 600.2ms\n",
      "Speed: 8.5ms preprocess, 600.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 motobikes, 5 pedestrians, 5 sedans, 600.0ms\n",
      "Speed: 0.0ms preprocess, 600.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 motobikes, 3 pedestrians, 6 sedans, 694.7ms\n",
      "Speed: 0.0ms preprocess, 694.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 motobikes, 4 pedestrians, 7 sedans, 649.8ms\n",
      "Speed: 14.2ms preprocess, 649.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 motobikes, 4 pedestrians, 8 sedans, 833.7ms\n",
      "Speed: 11.5ms preprocess, 833.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 motobikes, 4 pedestrians, 8 sedans, 771.0ms\n",
      "Speed: 0.0ms preprocess, 771.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 motobikes, 4 pedestrians, 8 sedans, 630.7ms\n",
      "Speed: 0.0ms preprocess, 630.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 motobikes, 4 pedestrians, 9 sedans, 600.0ms\n",
      "Speed: 0.0ms preprocess, 600.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 motobikes, 4 pedestrians, 8 sedans, 671.8ms\n",
      "Speed: 9.3ms preprocess, 671.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 motobikes, 4 pedestrians, 9 sedans, 664.9ms\n",
      "Speed: 0.0ms preprocess, 664.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 motobikes, 4 pedestrians, 9 sedans, 599.8ms\n",
      "Speed: 0.0ms preprocess, 599.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 motobikes, 4 pedestrians, 8 sedans, 663.5ms\n",
      "Speed: 0.0ms preprocess, 663.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Video processing completed or frame not available.\n",
      "Processing complete. Output saved to lane_detection_output.avi\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from LaneInput import LaneInput  # Class to input lane regions\n",
    "from PSMorg import SpeedEstimator2  # Updated SpeedEstimator2 class with time increment\n",
    "from time_utils import increment_time, get_time_from_xml  # Import utility functions\n",
    "\n",
    "# Initialize the YOLO model for object detection\n",
    "model = YOLO(\"best(3).pt\")  # Replace with the path to your YOLO model\n",
    "names = model.model.names  # List of class names for the YOLO model\n",
    "\n",
    "# Initialize video capture\n",
    "video_path = \"export6.mp4\"  # Replace with the path to your video\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "assert cap.isOpened(), f\"Error reading video file {video_path}\"\n",
    "\n",
    "# Get video properties (width, height, and FPS)\n",
    "w, h, fps = (int(cap.get(x)) for x in (cv2.CAP_PROP_FRAME_WIDTH, \n",
    "                                      cv2.CAP_PROP_FRAME_HEIGHT, \n",
    "                                      cv2.CAP_PROP_FPS))\n",
    "\n",
    "# Video writer to save the processed video with lane detection\n",
    "output_video = \"lane_detection_output.avi\"\n",
    "video_writer = cv2.VideoWriter(output_video, \n",
    "                               cv2.VideoWriter_fourcc(*\"mp4v\"), \n",
    "                               fps, (w, h))\n",
    "\n",
    "# Capture the first frame from the video to input lane points\n",
    "success, first_frame = cap.read()  # Read the first frame from the video\n",
    "#if not success or first_frame is None:\n",
    "    #raise ValueError(\"Failed to read the first frame from the video.\")\n",
    "\n",
    "# Initialize LaneInput to capture lane points\n",
    "lane_input = LaneInput()\n",
    "\n",
    "# Input the lane regions in the first frame\n",
    "#lane_input.input_lanes(first_frame)\n",
    "lane_regions, lane_centers = lane_input.get_lanes_and_centers()  # Get the captured lane regions and centers\n",
    "if not lane_regions:\n",
    "    #raise ValueError(\"No lane regions captured. Please ensure lanes are defined.\")\n",
    "\n",
    " print(\"Captured Lane Regions:\", lane_regions)\n",
    "\n",
    "# Load initial time from the XML file\n",
    "xml_file = r\"E:\\learn phython\\speed 2\\Speed-detection-of-vehicles\\C0148M01.XML\"\n",
    "current_time = get_time_from_xml(xml_file)\n",
    "\n",
    "# Initialize SpeedEstimator2\n",
    "lane_estimator = SpeedEstimator2(\n",
    "    names=names,\n",
    "    lane_regions=lane_regions,\n",
    "    lane_centers=lane_centers,  # Pass the lane centers as well\n",
    "    view_img=True,  # Display image flag\n",
    "    target_x=500,   # Define the X-coordinate target for lane estimation\n",
    "    csv_file=\"lane_log.csv\"  # Define the CSV file for logging\n",
    ")\n",
    "\n",
    "# Frame processing\n",
    "frame_counter = 0\n",
    "skip_frames = 10  # Number of frames to skip after processing one frame\n",
    "\n",
    "# Main loop for processing each video frame\n",
    "while cap.isOpened():\n",
    "    success, im0 = cap.read()  # Read the next frame\n",
    "    if not success:\n",
    "        print(\"Video processing completed or frame not available.\")\n",
    "        break\n",
    "\n",
    "    # Process every (skip_frames + 1)-th frame\n",
    "    if frame_counter % (skip_frames + 1) == 0:\n",
    "        # Perform object detection and tracking using the YOLO model\n",
    "        tracks = model.track(im0, persist=True)\n",
    "        \n",
    "        # Increment the current time based on the number of frames skipped\n",
    "        current_time = increment_time(current_time, skip_frames + 1, fps)\n",
    "        \n",
    "        # Pass the tracks and the frame to SpeedEstimator2's check_and_log_lanes function\n",
    "        im0 = lane_estimator.process_frame(im0, tracks, current_time)\n",
    "\n",
    "        # Display the processed frame with lane estimation\n",
    "        cv2.imshow(\"Live Output\", im0)\n",
    "\n",
    "        # Write the processed frame to the output video\n",
    "        video_writer.write(im0)\n",
    "\n",
    "    # Increment frame counter\n",
    "    frame_counter += 1\n",
    "\n",
    "    # Break the loop if the 'q' key is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        print(\"Processing terminated by user.\")\n",
    "        break\n",
    "\n",
    "# Release video capture and writer resources\n",
    "cap.release()\n",
    "video_writer.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(f\"Processing complete. Output saved to {output_video}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pedestrian",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
