{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LIVE STREAM INTO CLIPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import time\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from datetime import datetime\n",
    "\n",
    "# Load YOLOv8 model with tracking enabled\n",
    "model = YOLO(\"best(3).pt\")  # Use yolov8s.pt or larger versions if needed\n",
    "\n",
    "# Function to create a video writer\n",
    "def get_video_writer(filename, frame_size, fps=30):\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    return cv2.VideoWriter(filename, fourcc, fps, frame_size)\n",
    "\n",
    "# Initialize video capture (0 for webcam or replace with RTSP/HTTP stream URL)\n",
    "cap = cv2.VideoCapture('export6.mp4')\n",
    "\n",
    "# Object tracking dictionary\n",
    "active_recordings = {}\n",
    "frame_size = (int(cap.get(3)), int(cap.get(4)))\n",
    "frames_per_second = int(cap.get(cv2.CAP_PROP_FPS)) or 30  # Default to 30 if unknown\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # Run YOLOv8 inference with tracking\n",
    "    results = model.track(frame, persist=True)\n",
    "    \n",
    "    if results[0].boxes.id is not None:\n",
    "        track_ids = results[0].boxes.id.cpu().numpy()\n",
    "        detections = results[0].boxes.xyxy.cpu().numpy()\n",
    "        class_ids = results[0].boxes.cls.cpu().numpy()\n",
    "    else:\n",
    "        track_ids, detections, class_ids = [], [], []\n",
    "    \n",
    "    detected_objects = set()\n",
    "    for bbox, cls_id, track_id in zip(detections, class_ids, track_ids):\n",
    "        label = f\"{model.names[int(cls_id)]}_{int(track_id)}\"\n",
    "        detected_objects.add(label)\n",
    "        \n",
    "        # Draw bounding boxes\n",
    "        x1, y1, x2, y2 = map(int, bbox)\n",
    "        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "        cv2.putText(frame, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "        \n",
    "        # Start new recording if this specific object is not already being recorded\n",
    "        if label not in active_recordings:\n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            filename = f\"clip_{label}_{timestamp}.mp4\"\n",
    "            active_recordings[label] = get_video_writer(filename, frame_size, frames_per_second)\n",
    "            print(f\"Started recording: {filename}\")\n",
    "    \n",
    "    # Write frames to respective video files\n",
    "    for label in list(active_recordings.keys()):\n",
    "        if label in detected_objects:\n",
    "            active_recordings[label].write(frame)\n",
    "        else:\n",
    "            print(f\"Clip saved for {label}\")\n",
    "            active_recordings[label].release()\n",
    "            del active_recordings[label]\n",
    "    \n",
    "    # Show frame\n",
    "    cv2.imshow(\"YOLOv8 Live Stream\", frame)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Cleanup\n",
    "cap.release()\n",
    "for writer in active_recordings.values():\n",
    "    writer.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RUNNING PIPELINE ON DIRECTORY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reads the frame / add folder trajectory later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from LaneInput import LaneInput  # Class to input lane regions\n",
    "from PSMorg import SpeedEstimator2  # Updated SpeedEstimator2 class with time increment\n",
    "from time_utils import increment_time, get_time_from_xml  # Import utility functions\n",
    "\n",
    "# Initialize the YOLO model for object detection\n",
    "model = YOLO(r'E:\\learn phython\\speed 2\\Speed-detection-of-vehicles\\best(3).pt')  # Replace with the path to your YOLO model\n",
    "names = model.model.names  # List of class names for the YOLO model\n",
    "\n",
    "# Initialize video capture\n",
    "video_path = r'E:\\learn phython\\speed 2\\Speed-detection-of-vehicles\\C0148.MP4'\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "assert cap.isOpened(), f\"Error reading video file {video_path}\"\n",
    "\n",
    "# Get video properties (width, height, and FPS)\n",
    "w, h, fps = (int(cap.get(x)) for x in (cv2.CAP_PROP_FRAME_WIDTH, \n",
    "                                      cv2.CAP_PROP_FRAME_HEIGHT, \n",
    "                                      cv2.CAP_PROP_FPS))\n",
    "\n",
    "# Video writer to save the processed video with lane detection\n",
    "output_video = \"lane_detection_output.avi\"\n",
    "video_writer = cv2.VideoWriter(output_video, \n",
    "                               cv2.VideoWriter_fourcc(*\"mp4v\"), \n",
    "                               fps, (w, h))\n",
    "\n",
    "# Initialize LaneInput to capture lane points\n",
    "lane_input = LaneInput()\n",
    "\n",
    "# Capture the first frame from the video to input lane points\n",
    "success, first_frame = cap.read()\n",
    "if not success:\n",
    "    raise ValueError(\"Failed to read the first frame from the video.\")\n",
    "\n",
    "# Input the lane regions in the first frame\n",
    "lane_input.input_lanes(first_frame)\n",
    "lane_regions = lane_input.get_lanes()  # Get the captured lane regions\n",
    "print(\"Captured Lane Regions:\", lane_regions)\n",
    "\n",
    "# Load initial time from the XML file\n",
    "xml_file = r\"E:\\learn phython\\speed 2\\Speed-detection-of-vehicles\\C0148M01.XML\"\n",
    "current_time = get_time_from_xml(xml_file)\n",
    "\n",
    "# Initialize SpeedEstimator2\n",
    "lane_estimator = SpeedEstimator2(\n",
    "    names=names,\n",
    "    lane_regions=lane_regions,\n",
    "    view_img=True,  # Display image flag\n",
    "    target_x=500,   # Define the X-coordinate target for lane estimation\n",
    "     csv_file=\"lane_log.csv\" # Define the CSV file for logging\n",
    "    \n",
    ")\n",
    "\n",
    "# Frame processing\n",
    "frame_counter = 0\n",
    "skip_frames = 10  # Number of frames to skip after processing one frame\n",
    "\n",
    "# Main loop for processing each video frame\n",
    "while cap.isOpened():\n",
    "    success, im0 = cap.read()  # Read the next frame\n",
    "    if not success:\n",
    "        print(\"Video processing completed or frame not available.\")\n",
    "        break\n",
    "\n",
    "    # Process every (skip_frames + 1)-th frame\n",
    "    if frame_counter % (skip_frames + 1) == 0:\n",
    "        # Perform object detection and tracking using the YOLO model\n",
    "        tracks = model.track(im0, persist=True)\n",
    "        \n",
    "        # Increment the current time based on the number of frames skipped\n",
    "        current_time = increment_time(current_time, skip_frames + 1, fps)\n",
    "        \n",
    "        # Pass the tracks and the frame to SpeedEstimator2's check_and_log_lanes function\n",
    "        im0 = lane_estimator.check_and_log_lanes(im0, tracks, current_time)\n",
    "\n",
    "        # Display the processed frame with lane estimation\n",
    "        cv2.imshow(\"Live Output\", im0)\n",
    "\n",
    "        # Write the processed frame to the output video\n",
    "        video_writer.write(im0)\n",
    "\n",
    "    # Increment frame counter\n",
    "    frame_counter += 1\n",
    "\n",
    "    # Break the loop if the 'q' key is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        print(\"Processing terminated by user.\")\n",
    "        break\n",
    "\n",
    "# Release video capture and writer resources\n",
    "cap.release()\n",
    "video_writer.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(f\"Processing complete. Output saved to {output_video}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VEHICLE FEATURES\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lane_input' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 9\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPSMorg\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SpeedEstimator2  \u001b[38;5;66;03m# Updated SpeedEstimator2 class with time increment\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtime_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m increment_time, get_time_from_xml  \u001b[38;5;66;03m# Import utility functions\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m \u001b[43mlane_input\u001b[49m\u001b[38;5;241m.\u001b[39minput_lanes(first_frame)\n\u001b[0;32m     10\u001b[0m lane_regions \u001b[38;5;241m=\u001b[39m lane_input\u001b[38;5;241m.\u001b[39mget_lanes()  \u001b[38;5;66;03m# Get the captured lane regions\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCaptured Lane Regions:\u001b[39m\u001b[38;5;124m\"\u001b[39m, lane_regions)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'lane_input' is not defined"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from LaneInput import LaneInput  # Class to input lane regions\n",
    "from PSMorg import SpeedEstimator2  # Updated SpeedEstimator2 class with time increment\n",
    "from time_utils import increment_time, get_time_from_xml  # Import utility functions\n",
    "\n",
    "\n",
    "lane_input.input_lanes(first_frame)\n",
    "lane_regions = lane_input.get_lanes()  # Get the captured lane regions\n",
    "print(\"Captured Lane Regions:\", lane_regions)\n",
    "\n",
    "# Load initial time from the XML file\n",
    "xml_file = r\"E:\\learn phython\\speed 2\\Speed-detection-of-vehicles\\C0148M01.XML\"\n",
    "current_time = get_time_from_xml(xml_file)\n",
    "\n",
    "# Initialize SpeedEstimator2\n",
    "lane_estimator = SpeedEstimator2(\n",
    "    names=names,\n",
    "    lane_regions=lane_regions,\n",
    "    view_img=True,  # Display image flag\n",
    "    target_x=500,   # Define the X-coordinate target for lane estimation\n",
    "     csv_file=\"lane_log.csv\" # Define the CSV file for logging\n",
    "    \n",
    ")\n",
    "\n",
    "# Frame processing\n",
    "frame_counter = 0\n",
    "skip_frames = 10  # Number of frames to skip after processing one frame\n",
    "\n",
    "# Main loop for processing each video frame\n",
    "while cap.isOpened():\n",
    "    success, im0 = cap.read()  # Read the next frame\n",
    "    if not success:\n",
    "        print(\"Video processing completed or frame not available.\")\n",
    "        break\n",
    "\n",
    "    # Process every (skip_frames + 1)-th frame\n",
    "    if frame_counter % (skip_frames + 1) == 0:\n",
    "        # Perform object detection and tracking using the YOLO model\n",
    "        tracks = model.track(im0, persist=True)\n",
    "        \n",
    "        # Increment the current time based on the number of frames skipped\n",
    "        current_time = increment_time(current_time, skip_frames + 1, fps)\n",
    "        \n",
    "        # Pass the tracks and the frame to SpeedEstimator2's check_and_log_lanes function\n",
    "        im0 = lane_estimator.check_and_log_lanes(im0, tracks, current_time)\n",
    "\n",
    "        # Display the processed frame with lane estimation\n",
    "        cv2.imshow(\"Live Output\", im0)\n",
    "\n",
    "        # Write the processed frame to the output video\n",
    "        video_writer.write(im0)\n",
    "\n",
    "    # Increment frame counter\n",
    "    frame_counter += 1\n",
    "\n",
    "    # Break the loop if the 'q' key is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        print(\"Processing terminated by user.\")\n",
    "        break\n",
    "\n",
    "# Release video capture and writer resources\n",
    "cap.release()\n",
    "video_writer.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(f\"Processing complete. Output saved to {output_video}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pedestrian",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
