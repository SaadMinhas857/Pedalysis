{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LIVE STREAM INTO CLIPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\SAAD\\anaconda3\\envs\\pedestrian\\lib\\site-packages\\torch\\__init__.py:2143\u001b[0m\n\u001b[0;32m   2141\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m library\n\u001b[0;32m   2142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m TYPE_CHECKING:\n\u001b[1;32m-> 2143\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _meta_registrations\n\u001b[0;32m   2145\u001b[0m \u001b[38;5;66;03m# Enable CUDA Sanitizer\u001b[39;00m\n\u001b[0;32m   2146\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTORCH_CUDA_SANITIZER\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron:\n",
      "File \u001b[1;32mc:\\Users\\SAAD\\anaconda3\\envs\\pedestrian\\lib\\site-packages\\torch\\_meta_registrations.py:9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_prims_common\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SymBool, SymFloat, Tensor\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_decomp\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     10\u001b[0m     _add_op_to_registry,\n\u001b[0;32m     11\u001b[0m     _convert_out_params,\n\u001b[0;32m     12\u001b[0m     global_decomposition_table,\n\u001b[0;32m     13\u001b[0m     meta_table,\n\u001b[0;32m     14\u001b[0m )\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_ops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OpOverload\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_prims\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _prim_elementwise_meta, ELEMENTWISE_PRIM_TYPE_PROMOTION_KIND\n",
      "File \u001b[1;32mc:\\Users\\SAAD\\anaconda3\\envs\\pedestrian\\lib\\site-packages\\torch\\_decomp\\__init__.py:245\u001b[0m\n\u001b[0;32m    241\u001b[0m             decompositions\u001b[38;5;241m.\u001b[39mpop(op, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    244\u001b[0m \u001b[38;5;66;03m# populate the table\u001b[39;00m\n\u001b[1;32m--> 245\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_decomp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdecompositions\u001b[39;00m\n\u001b[0;32m    246\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_refs\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;66;03m# See NOTE [Core ATen Ops]\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m    251\u001b[0m \u001b[38;5;66;03m# list was copied from torch/_inductor/decomposition.py\u001b[39;00m\n\u001b[0;32m    252\u001b[0m \u001b[38;5;66;03m# excluding decompositions that results in prim ops\u001b[39;00m\n\u001b[0;32m    253\u001b[0m \u001b[38;5;66;03m# Resulting opset of decomposition is core aten ops\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\SAAD\\anaconda3\\envs\\pedestrian\\lib\\site-packages\\torch\\_decomp\\decompositions.py:12\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Any, Callable, cast, Iterable, List, Optional, Tuple, Union\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_prims\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mprims\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_prims_common\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mF\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\SAAD\\anaconda3\\envs\\pedestrian\\lib\\site-packages\\torch\\_prims\\__init__.py:715\u001b[0m\n\u001b[0;32m    701\u001b[0m erf \u001b[38;5;241m=\u001b[39m _make_elementwise_unary_prim(\n\u001b[0;32m    702\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merf\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    703\u001b[0m     impl_aten\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39merf,\n\u001b[0;32m    704\u001b[0m     doc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    705\u001b[0m     type_promotion\u001b[38;5;241m=\u001b[39mELEMENTWISE_PRIM_TYPE_PROMOTION_KIND\u001b[38;5;241m.\u001b[39mDEFAULT,\n\u001b[0;32m    706\u001b[0m )\n\u001b[0;32m    708\u001b[0m erf_inv \u001b[38;5;241m=\u001b[39m _make_elementwise_unary_prim(\n\u001b[0;32m    709\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merf_inv\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    710\u001b[0m     impl_aten\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mspecial\u001b[38;5;241m.\u001b[39merfinv,\n\u001b[0;32m    711\u001b[0m     doc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    712\u001b[0m     type_promotion\u001b[38;5;241m=\u001b[39mELEMENTWISE_PRIM_TYPE_PROMOTION_KIND\u001b[38;5;241m.\u001b[39mDEFAULT,\n\u001b[0;32m    713\u001b[0m )\n\u001b[1;32m--> 715\u001b[0m erfc \u001b[38;5;241m=\u001b[39m \u001b[43m_make_elementwise_unary_prim\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    716\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43merfc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    717\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimpl_aten\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspecial\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merfc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    718\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdoc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    719\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtype_promotion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mELEMENTWISE_PRIM_TYPE_PROMOTION_KIND\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDEFAULT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    720\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m    722\u001b[0m erfcx \u001b[38;5;241m=\u001b[39m _make_elementwise_unary_prim(\n\u001b[0;32m    723\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merfcx\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    724\u001b[0m     impl_aten\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mspecial\u001b[38;5;241m.\u001b[39merfcx,\n\u001b[0;32m    725\u001b[0m     doc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    726\u001b[0m     type_promotion\u001b[38;5;241m=\u001b[39mELEMENTWISE_PRIM_TYPE_PROMOTION_KIND\u001b[38;5;241m.\u001b[39mDEFAULT,\n\u001b[0;32m    727\u001b[0m )\n\u001b[0;32m    729\u001b[0m exp \u001b[38;5;241m=\u001b[39m _make_elementwise_unary_prim(\n\u001b[0;32m    730\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexp\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    731\u001b[0m     impl_aten\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mexp,\n\u001b[0;32m    732\u001b[0m     doc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    733\u001b[0m     type_promotion\u001b[38;5;241m=\u001b[39mELEMENTWISE_PRIM_TYPE_PROMOTION_KIND\u001b[38;5;241m.\u001b[39mDEFAULT,\n\u001b[0;32m    734\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\SAAD\\anaconda3\\envs\\pedestrian\\lib\\site-packages\\torch\\_prims\\__init__.py:472\u001b[0m, in \u001b[0;36m_make_elementwise_unary_prim\u001b[1;34m(name, type_promotion, **kwargs)\u001b[0m\n\u001b[0;32m    465\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_make_elementwise_unary_prim\u001b[39m(\n\u001b[0;32m    466\u001b[0m     name: \u001b[38;5;28mstr\u001b[39m, \u001b[38;5;241m*\u001b[39m, type_promotion: ELEMENTWISE_PRIM_TYPE_PROMOTION_KIND, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    467\u001b[0m ):\n\u001b[0;32m    468\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    469\u001b[0m \u001b[38;5;124;03m    Creates an elementwise unary prim.\u001b[39;00m\n\u001b[0;32m    470\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 472\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _make_prim(\n\u001b[0;32m    473\u001b[0m         schema\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m(Tensor self) -> Tensor\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    474\u001b[0m         meta\u001b[38;5;241m=\u001b[39mpartial(_prim_elementwise_meta, type_promotion\u001b[38;5;241m=\u001b[39mtype_promotion),\n\u001b[0;32m    475\u001b[0m         return_type\u001b[38;5;241m=\u001b[39mRETURN_TYPE\u001b[38;5;241m.\u001b[39mNEW,\n\u001b[0;32m    476\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    477\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\SAAD\\anaconda3\\envs\\pedestrian\\lib\\site-packages\\torch\\_prims\\__init__.py:320\u001b[0m, in \u001b[0;36m_make_prim\u001b[1;34m(schema, return_type, meta, impl_aten, doc, tags, use_old_custom_ops_api)\u001b[0m\n\u001b[0;32m    318\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m arg\u001b[38;5;241m.\u001b[39malias_info \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m arg\u001b[38;5;241m.\u001b[39malias_info\u001b[38;5;241m.\u001b[39mis_write:\n\u001b[0;32m    319\u001b[0m             mutates_args\u001b[38;5;241m.\u001b[39mappend(arg\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m--> 320\u001b[0m     prim_def \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlibrary\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcustom_op\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    321\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprims::\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    322\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_prim_impl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    323\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmutates_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmutates_args\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    324\u001b[0m \u001b[43m        \u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    325\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    326\u001b[0m     prim_def\u001b[38;5;241m.\u001b[39mregister_fake(meta)\n\u001b[0;32m    328\u001b[0m _prim_packet \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_ops\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39mprims, name)\n",
      "File \u001b[1;32mc:\\Users\\SAAD\\anaconda3\\envs\\pedestrian\\lib\\site-packages\\torch\\_library\\custom_ops.py:142\u001b[0m, in \u001b[0;36mcustom_op\u001b[1;34m(name, fn, mutates_args, device_types, schema)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m inner\n\u001b[1;32m--> 142\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\SAAD\\anaconda3\\envs\\pedestrian\\lib\\site-packages\\torch\\_library\\custom_ops.py:123\u001b[0m, in \u001b[0;36mcustom_op.<locals>.inner\u001b[1;34m(fn)\u001b[0m\n\u001b[0;32m    121\u001b[0m     schema_str \u001b[38;5;241m=\u001b[39m schema\n\u001b[0;32m    122\u001b[0m namespace, opname \u001b[38;5;241m=\u001b[39m name\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m::\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 123\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mCustomOpDef\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnamespace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m schema \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    125\u001b[0m     \u001b[38;5;66;03m# Check that schema's alias annotations match those of `mutates_args`.\u001b[39;00m\n\u001b[0;32m    126\u001b[0m     expected \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\SAAD\\anaconda3\\envs\\pedestrian\\lib\\site-packages\\torch\\_library\\custom_ops.py:169\u001b[0m, in \u001b[0;36mCustomOpDef.__init__\u001b[1;34m(self, namespace, name, schema, fn)\u001b[0m\n\u001b[0;32m    166\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_fn: Optional[Callable] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lib \u001b[38;5;241m=\u001b[39m get_library_allowing_overwrite(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_namespace, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name)\n\u001b[1;32m--> 169\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_register_to_dispatcher\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    170\u001b[0m OPDEFS[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_qualname] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\SAAD\\anaconda3\\envs\\pedestrian\\lib\\site-packages\\torch\\_library\\custom_ops.py:473\u001b[0m, in \u001b[0;36mCustomOpDef._register_to_dispatcher\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    465\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    466\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThere was no fake impl registered for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    467\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis is necessary for torch.compile/export/fx tracing to work. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    468\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease use `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.register_fake` to add an \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    469\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfake impl.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    470\u001b[0m         )\n\u001b[0;32m    471\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_abstract_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 473\u001b[0m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_register_fake\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfake_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacklevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    475\u001b[0m autograd_impl \u001b[38;5;241m=\u001b[39m _library\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mmake_autograd_impl(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_opoverload, \u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    476\u001b[0m lib\u001b[38;5;241m.\u001b[39mimpl(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name, autograd_impl, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAutograd\u001b[39m\u001b[38;5;124m\"\u001b[39m, with_keyset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\SAAD\\anaconda3\\envs\\pedestrian\\lib\\site-packages\\torch\\library.py:135\u001b[0m, in \u001b[0;36mLibrary._register_fake\u001b[1;34m(self, op_name, fn, _stacklevel)\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_register_fake\u001b[39m(\u001b[38;5;28mself\u001b[39m, op_name, fn, _stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m    134\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m'''Registers the fake impl for an operator defined in the library.'''\u001b[39;00m\n\u001b[1;32m--> 135\u001b[0m     source \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_library\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_source\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_stacklevel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    136\u001b[0m     frame \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39m_getframe(_stacklevel)\n\u001b[0;32m    137\u001b[0m     caller_module \u001b[38;5;241m=\u001b[39m inspect\u001b[38;5;241m.\u001b[39mgetmodule(frame)\n",
      "File \u001b[1;32mc:\\Users\\SAAD\\anaconda3\\envs\\pedestrian\\lib\\site-packages\\torch\\_library\\utils.py:42\u001b[0m, in \u001b[0;36mget_source\u001b[1;34m(stacklevel)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_source\u001b[39m(stacklevel: \u001b[38;5;28mint\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[0;32m     34\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get a string that represents the caller.\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \n\u001b[0;32m     36\u001b[0m \u001b[38;5;124;03m    Example: \"/path/to/foo.py:42\"\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;124;03m    etc.\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 42\u001b[0m     frame \u001b[38;5;241m=\u001b[39m \u001b[43minspect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetframeinfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getframe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstacklevel\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     43\u001b[0m     source \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mframe\u001b[38;5;241m.\u001b[39mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mframe\u001b[38;5;241m.\u001b[39mlineno\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m source\n",
      "File \u001b[1;32mc:\\Users\\SAAD\\anaconda3\\envs\\pedestrian\\lib\\inspect.py:1620\u001b[0m, in \u001b[0;36mgetframeinfo\u001b[1;34m(frame, context)\u001b[0m\n\u001b[0;32m   1617\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m isframe(frame):\n\u001b[0;32m   1618\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m is not a frame or traceback object\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(frame))\n\u001b[1;32m-> 1620\u001b[0m filename \u001b[38;5;241m=\u001b[39m \u001b[43mgetsourcefile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mor\u001b[39;00m getfile(frame)\n\u001b[0;32m   1621\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m context \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1622\u001b[0m     start \u001b[38;5;241m=\u001b[39m lineno \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m context\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\SAAD\\anaconda3\\envs\\pedestrian\\lib\\inspect.py:826\u001b[0m, in \u001b[0;36mgetsourcefile\u001b[1;34m(object)\u001b[0m\n\u001b[0;32m    823\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28many\u001b[39m(filename\u001b[38;5;241m.\u001b[39mendswith(s) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m\n\u001b[0;32m    824\u001b[0m              importlib\u001b[38;5;241m.\u001b[39mmachinery\u001b[38;5;241m.\u001b[39mEXTENSION_SUFFIXES):\n\u001b[0;32m    825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 826\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexists\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    827\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m filename\n\u001b[0;32m    828\u001b[0m \u001b[38;5;66;03m# only return a non-existent filename if the module has a PEP 302 loader\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\SAAD\\anaconda3\\envs\\pedestrian\\lib\\genericpath.py:19\u001b[0m, in \u001b[0;36mexists\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Test whether a path exists.  Returns False for broken symbolic links\"\"\"\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 19\u001b[0m     \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mOSError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import time\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from datetime import datetime\n",
    "\n",
    "# Load YOLOv8 model with tracking enabled\n",
    "model = YOLO(\"best(3).pt\")  # Use yolov8s.pt or larger versions if needed\n",
    "\n",
    "# Function to create a video writer\n",
    "def get_video_writer(filename, frame_size, fps=30):\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    return cv2.VideoWriter(filename, fourcc, fps, frame_size)\n",
    "\n",
    "# Initialize video capture (0 for webcam or replace with RTSP/HTTP stream URL)\n",
    "cap = cv2.VideoCapture('export6.mp4')\n",
    "\n",
    "# Object tracking dictionary\n",
    "active_recordings = {}\n",
    "frame_size = (int(cap.get(3)), int(cap.get(4)))\n",
    "frames_per_second = int(cap.get(cv2.CAP_PROP_FPS)) or 30  # Default to 30 if unknown\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # Run YOLOv8 inference with tracking\n",
    "    results = model.track(frame, persist=True)\n",
    "    \n",
    "    if results[0].boxes.id is not None:\n",
    "        track_ids = results[0].boxes.id.cpu().numpy()\n",
    "        detections = results[0].boxes.xyxy.cpu().numpy()\n",
    "        class_ids = results[0].boxes.cls.cpu().numpy()\n",
    "    else:\n",
    "        track_ids, detections, class_ids = [], [], []\n",
    "    \n",
    "    detected_objects = set()\n",
    "    for bbox, cls_id, track_id in zip(detections, class_ids, track_ids):\n",
    "        label = f\"{model.names[int(cls_id)]}_{int(track_id)}\"\n",
    "        detected_objects.add(label)\n",
    "        \n",
    "        # Draw bounding boxes\n",
    "        x1, y1, x2, y2 = map(int, bbox)\n",
    "        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "        cv2.putText(frame, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "        \n",
    "        # Start new recording if this specific object is not already being recorded\n",
    "        if label not in active_recordings:\n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            filename = f\"clip_{label}_{timestamp}.mp4\"\n",
    "            active_recordings[label] = get_video_writer(filename, frame_size, frames_per_second)\n",
    "            print(f\"Started recording: {filename}\")\n",
    "    \n",
    "    # Write frames to respective video files\n",
    "    for label in list(active_recordings.keys()):\n",
    "        if label in detected_objects:\n",
    "            active_recordings[label].write(frame)\n",
    "        else:\n",
    "            print(f\"Clip saved for {label}\")\n",
    "            active_recordings[label].release()\n",
    "            del active_recordings[label]\n",
    "    \n",
    "    # Show frame\n",
    "    cv2.imshow(\"YOLOv8 Live Stream\", frame)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Cleanup\n",
    "cap.release()\n",
    "for writer in active_recordings.values():\n",
    "    writer.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RUNNING PIPELINE ON DIRECTORY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reads the frame / add folder trajectory later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pedestrian 1 traveled 0.71 meters at 0.07 m/s.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from pedestrianpsm.LaneInput import LaneInput  # Class to input lane regions\n",
    "from carpsm.PSMorg import SpeedEstimator2  # Updated SpeedEstimator2 class with time increment\n",
    "from carpsm.time_utils import increment_time, get_time_from_xml  # Import utility functions\n",
    "from volume.volume import VehicleDetectionWithTracks \n",
    "from pedestrianpsm import LaneChecker\n",
    "from pedestrianpsm.PSMorg import PEDESTRIANESTIMATOR\n",
    "from pedestrianfeatures.PedestrianOrganization import PedestrianSpeedEstimator\n",
    "from vehicle.Speed_3 import ObjectTracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize the YOLO model for object detection\n",
    "model = YOLO(r'E:\\learn phython\\speed 2\\Speed-detection-of-vehicles\\best(3).pt')  # Replace with the path to your YOLO model\n",
    "names = model.model.names  # List of class names for the YOLO model\n",
    "\n",
    "# Initialize video capture\n",
    "video_path = r'E:\\learn phython\\fydp final\\export6.mp4'\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "assert cap.isOpened(), f\"Error reading video file {video_path}\"\n",
    "\n",
    "# Get video properties (width, height, and FPS)\n",
    "w, h, fps = (int(cap.get(x)) for x in (cv2.CAP_PROP_FRAME_WIDTH, \n",
    "                                      cv2.CAP_PROP_FRAME_HEIGHT, \n",
    "                                      cv2.CAP_PROP_FPS))\n",
    "\n",
    "# Video writer to save the processed video with lane detection\n",
    "output_video = \"lane_detection_output.avi\"\n",
    "video_writer = cv2.VideoWriter(output_video, \n",
    "                               cv2.VideoWriter_fourcc(*\"mp4v\"), \n",
    "                               fps, (w, h))\n",
    "frame_counter = 0\n",
    "skip_frames = 10  # Number of frames to skip after processing one frame\n",
    "# Initialize LaneInput to capture lane points\n",
    "\n",
    "# Capture the first frame from the video to input lane points\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LANE INPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please input the number of lanes:\n",
      "No lanes inputted. Using default lane regions.\n",
      "Default Lane Regions: [((509, 2), (622, 832), (988, 832), (731, 3)), ((733, 4), (987, 832), (1342, 833), (969, 5)), ((969, 5), (1344, 832), (1528, 832), (1233, 2))]\n",
      "Lane Centers: [(712, 417), (1007, 418), (1268, 417)]\n",
      "Captured Lane Regions: [((509, 2), (622, 832), (988, 832), (731, 3)), ((733, 4), (987, 832), (1342, 833), (969, 5)), ((969, 5), (1344, 832), (1528, 832), (1233, 2))] lane Centers: [(712, 417), (1007, 418), (1268, 417)]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "ObjectTracking.__init__() got an unexpected keyword argument 'names'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 36\u001b[0m\n\u001b[0;32m     17\u001b[0m current_time \u001b[38;5;241m=\u001b[39m get_time_from_xml(xml_file)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Initialize SpeedEstimator2 for VehICle PSM\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# lane_estimator = SpeedEstimator2(\u001b[39;00m\n\u001b[0;32m     21\u001b[0m    \u001b[38;5;66;03m# names=names,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m#)\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# Frame processing\u001b[39;00m\n\u001b[1;32m---> 36\u001b[0m speed_calculator \u001b[38;5;241m=\u001b[39m \u001b[43mObjectTracking\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mnames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnames\u001b[49m\u001b[43m   \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m#pedestrian_speed = PedestrianSpeedEstimator (\u001b[39;00m\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;66;03m#names=names,\u001b[39;00m\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;66;03m#lane_regions=lane_regions ,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     43\u001b[0m \n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# Main loop for processing each video frame\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: ObjectTracking.__init__() got an unexpected keyword argument 'names'"
     ]
    }
   ],
   "source": [
    "lane_input = LaneInput()\n",
    "\n",
    "success, first_frame = cap.read()\n",
    "if not success:\n",
    "    raise ValueError(\"Failed to read the first frame from the video.\")\n",
    "\n",
    "# Input the lane regions in the first frame\n",
    "lane_input.input_lanes(first_frame)\n",
    "lane_regions , lane_centers = lane_input.get_lanes_and_centers()  # Get the captured lane regions\n",
    "print(\"Captured Lane Regions:\", lane_regions ,\"lane Centers:\" , lane_centers)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Load initial time from the XML file\n",
    "xml_file = r\"E:\\learn phython\\speed 2\\Speed-detection-of-vehicles\\C0148M01.XML\"\n",
    "current_time = get_time_from_xml(xml_file)\n",
    "\n",
    "# Initialize SpeedEstimator2 for VehICle PSM\n",
    "# lane_estimator = SpeedEstimator2(\n",
    "   # names=names,\n",
    "   # lane_regions=lane_regions,\n",
    "   # view_img=True,  # Display image flag\n",
    "   # target_x=500,   # Define the X-coordinate target for lane estimation\n",
    "   #  csv_file=\"lane_log.csv\" # Define the CSV file for logging)\n",
    "\n",
    "# Initialize SpeedEstimator2 for Pedestrian PSM\n",
    "#lane_estimator = PEDESTRIANESTIMATOR(\n",
    "    #names=names,\n",
    "    #lane_regions=lane_regions,\n",
    "    #lane_centers= lane_centers,\n",
    "    #view_img=True,  # Display image flag   # Define the X-coordinate target for lane estimation\n",
    "    #csv_file=\"lane_log.csv\"  # Define the CSV file for logging\n",
    "#)\n",
    "# Frame processing\n",
    "speed_calculator = ObjectTracking ()\n",
    "#pedestrian_speed = PedestrianSpeedEstimator (\n",
    "    #names=names,\n",
    "    #lane_regions=lane_regions ,\n",
    "   # current_time = current_time ,\n",
    "  #  view_img=True,  # Display image flag   # Define the X-coordinate target for lane estimation\n",
    " #   csv_file=\"lane_log.csv\"  # Define the CSV file for logging\n",
    "\n",
    "# Main loop for processing each video frame\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 6 motobikes, 2 pedestrians, 8 sedans, 678.8ms\n",
      "Speed: 0.0ms preprocess, 678.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: None\n",
      "names: {0: 'biker', 1: 'bus', 2: 'motobike', 3: 'pedestrian', 4: 'sedan', 5: 'taxi', 6: 'truck'}\n",
      "obb: None\n",
      "orig_img: array([[[144, 136, 136],\n",
      "        [145, 137, 137],\n",
      "        [149, 141, 141],\n",
      "        ...,\n",
      "        [ 35,  30,  29],\n",
      "        [ 34,  29,  28],\n",
      "        [ 31,  26,  25]],\n",
      "\n",
      "       [[145, 137, 137],\n",
      "        [148, 140, 140],\n",
      "        [150, 142, 142],\n",
      "        ...,\n",
      "        [ 36,  31,  30],\n",
      "        [ 36,  31,  30],\n",
      "        [ 35,  30,  29]],\n",
      "\n",
      "       [[146, 138, 138],\n",
      "        [148, 140, 140],\n",
      "        [150, 142, 142],\n",
      "        ...,\n",
      "        [ 36,  31,  30],\n",
      "        [ 36,  31,  30],\n",
      "        [ 37,  32,  31]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[100,  97,  96],\n",
      "        [100,  97,  96],\n",
      "        [102,  99,  98],\n",
      "        ...,\n",
      "        [124, 116, 111],\n",
      "        [126, 115, 112],\n",
      "        [126, 115, 112]],\n",
      "\n",
      "       [[100,  97,  96],\n",
      "        [100,  97,  96],\n",
      "        [102,  99,  98],\n",
      "        ...,\n",
      "        [123, 115, 110],\n",
      "        [126, 115, 112],\n",
      "        [125, 114, 111]],\n",
      "\n",
      "       [[102,  99,  98],\n",
      "        [100,  97,  96],\n",
      "        [102,  99,  98],\n",
      "        ...,\n",
      "        [123, 115, 110],\n",
      "        [126, 115, 112],\n",
      "        [126, 115, 112]]], dtype=uint8)\n",
      "orig_shape: (1080, 1920)\n",
      "path: 'image0.jpg'\n",
      "probs: None\n",
      "save_dir: 'e:\\\\learn phython\\\\pedestrian\\\\Speed-detection-of-vehicles\\\\runs\\\\detect\\\\track'\n",
      "speed: {'preprocess': 0.0, 'inference': 678.8344383239746, 'postprocess': 2.997159957885742}]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array would exceed the maximum number of dimension of 32.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 27\u001b[0m\n\u001b[0;32m     13\u001b[0m     current_time \u001b[38;5;241m=\u001b[39m increment_time(current_time, skip_frames \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, fps)\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;66;03m#CAR PSM CODE THAT RESULTS IN EXCEL FILES\u001b[39;00m\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;66;03m# Pass the tracks and the frame to SpeedEstimator2's check_and_log_lanes function\u001b[39;00m\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;66;03m#im0 = lane_estimator.check_and_log_lanes(im0, tracks, current_time)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     25\u001b[0m \n\u001b[0;32m     26\u001b[0m    \u001b[38;5;66;03m#Vehicle Features\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m     im0\u001b[38;5;241m=\u001b[39m\u001b[43mspeed_calculator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_vehicle_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtracks\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mim0\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcurrent_time\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;66;03m#FLOW\u001b[39;00m\n\u001b[0;32m     30\u001b[0m    \u001b[38;5;66;03m# = VehicleDetectionWithTracks(tracks, start_time=\"2025-02-27 08:00:00\", frame_rate=30)\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     39\u001b[0m \n\u001b[0;32m     40\u001b[0m     \u001b[38;5;66;03m# Display the processed frame with lane estimation\u001b[39;00m\n\u001b[0;32m     41\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLive Output\u001b[39m\u001b[38;5;124m\"\u001b[39m, im0)\n",
      "File \u001b[1;32me:\\learn phython\\fydp final\\vehicle\\Speed_3.py:76\u001b[0m, in \u001b[0;36mVehicleSpeedCalculator.update_vehicle_data\u001b[1;34m(self, im0, tracks, current_time)\u001b[0m\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mextract_tracks(tracks)\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(im0, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m---> 76\u001b[0m      im0 \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim0\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;66;03m# Ensure im0 is a contiguous array (needed by Annotator)\u001b[39;00m\n\u001b[0;32m     79\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m im0\u001b[38;5;241m.\u001b[39mflags[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC_CONTIGUOUS\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence. The requested array would exceed the maximum number of dimension of 32."
     ]
    }
   ],
   "source": [
    "while cap.isOpened():\n",
    "    success, im0 = cap.read()  # Read the next frame\n",
    "    if not success:\n",
    "        print(\"Video processing completed or frame not available.\")\n",
    "        break\n",
    "\n",
    "    # Process every (skip_frames + 1)-th frame\n",
    "    if frame_counter % (skip_frames + 1) == 0:\n",
    "        # Perform object detection and tracking using the YOLO model\n",
    "        tracks = model.track(im0, persist=True)\n",
    "        print(tracks)\n",
    "        # Increment the current time based on the number of frames skipped\n",
    "        current_time = increment_time(current_time, skip_frames + 1, fps)\n",
    "        \n",
    "        #CAR PSM CODE THAT RESULTS IN EXCEL FILES\n",
    "        # Pass the tracks and the frame to SpeedEstimator2's check_and_log_lanes function\n",
    "        #im0 = lane_estimator.check_and_log_lanes(im0, tracks, current_time)\n",
    "        \n",
    "        #PEDESTRIAN PSM CODE\n",
    "        #im0 = lane_estimator.process_frame(im0, tracks, current_time)\n",
    "        # Display the processed frame with lane estimation\n",
    "       \n",
    "       #PEDESTRIAN FEATURES\n",
    "       \n",
    "\n",
    "       #Vehicle Features\n",
    "        im0=speed_calculator.process_video(tracks , im0 , current_time)\n",
    "        \n",
    "        #FLOW\n",
    "       # = VehicleDetectionWithTracks(tracks, start_time=\"2025-02-27 08:00:00\", frame_rate=30)\n",
    "\n",
    "# Calculate the traffic flow based on the provided tracks\n",
    "        #vehicles_per_hour, interval_vehicles, max_flow_interval, max_flow_count = vehicle_detector.calculate_traffic_flow()\n",
    "\n",
    "# Output the results\n",
    "    #print(\"Total vehicles per hour:\")\n",
    "    #for hour, count in vehicles_per_hour.items():\n",
    "     #print(f\"{hour.strftime('%Y-%m-%d %H:%M:%S')} - {count} vehicles\")\n",
    "\n",
    "        # Display the processed frame with lane estimation\n",
    "    cv2.imshow(\"Live Output\", im0)\n",
    "    cv2.waitKey(1)\n",
    "        # Write the processed frame to the output video\n",
    "    video_writer.write(im0)\n",
    "\n",
    "    # Increment frame counter\n",
    "    frame_counter += 1\n",
    "\n",
    "    # Break the loop if the 'q' key is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        print(\"Processing terminated by user.\")\n",
    "        break\n",
    "\n",
    "# Release video capture and writer resources\n",
    "cap.release()\n",
    "video_writer.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(f\"Processing complete. Output saved to {output_video}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VEHICLE FEATURES\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pedestrian",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
